#!/usr/bin/env python3
# {{{ Header notes.

"""
gits.py - Python version of 'gits' repository management script, with icons.

Features:
  - Pre-flight YAML validation (clear errors for malformed config)
  - Clone, delete, pull, clean, convert encoding, list stashes, and more
  - All repo directories are in $HOME/group/alias
  - Parallel actions, dry-run and verbose support
  - Beautiful, informative icons for every status/action

Author: Traap
Date: 2025-05-18
"""

# -------------------------------------------------------------------------- }}}
# {{{ Import statements

import argparse
import sys
import os
import yaml
import subprocess
import shutil
from concurrent.futures import ThreadPoolExecutor, as_completed

# -------------------------------------------------------------------------- }}}
# {{{ ICONS

ICON_CLEAN    = "üßπ"
ICON_CLONE    = "‚û°Ô∏è"
ICON_CONVERT  = "üîÑ"
ICON_DELETE   = "‚ùå"
ICON_DONE     = "‚úÖ"
ICON_ERROR    = "‚ùå"
ICON_INFO     = "‚ÑπÔ∏è"
ICON_PULL     = "‚¨ÜÔ∏è"
ICON_STASH    = "üì¶"
ICON_SUCCESS  = "‚úÖ"
ICON_TIME     = "‚è±Ô∏è"
ICON_WARNING  = "‚ö†Ô∏è"

# -------------------------------------------------------------------------- }}}
# {{{ Options class holds all CLI options.

class Options:
    """
    Holds all CLI options parsed from argparse.
    Makes it easy to pass all user settings to helpers.
    """
    def __init__(self, args):
        # Copy all argparse fields into this class
        for k, v in vars(args).items():
            setattr(self, k, v)

#  ------------------------------------------------------------------------- }}}
# {{{ Parse arguments

def parse_args():
    """
    Set up argument parser for CLI options and return the parsed args.
    """
    parser = argparse.ArgumentParser(add_help=False, usage=argparse.SUPPRESS)
    parser.add_argument('-h', action='store_true')
    parser.add_argument('-l', action='store_true')
    parser.add_argument('-R', action='store_true')
    parser.add_argument('-r', metavar='name', type=str)
    parser.add_argument('-d', action='store_true')
    parser.add_argument('-s', action='store_true')
    parser.add_argument('-u', action='store_true')
    parser.add_argument('-v', action='store_true')
    parser.add_argument('-x', action='store_true')
    group = parser.add_mutually_exclusive_group()
    group.add_argument('-c', action='store_true')
    group.add_argument('-p', action='store_true')
    parser.add_argument('-n', action='store_true')
    args = parser.parse_args()
    return args

# -------------------------------------------------------------------------- }}}
# {{{ Load Repository Yaml File

def load_repos_yaml(filepath):
    """
    Load the repository locations YAML file.
    """
    if not os.path.exists(filepath):
        print(f"{ICON_ERROR} Repo locations file not found: {filepath}")
        sys.exit(1)
    with open(filepath, 'r') as f:
        return yaml.safe_load(f)

#  ------------------------------------------------------------------------- }}}
# {{{ Validate Repository Yaml File

def validate_repo_data(repo_data):
    """
    Ensures every entry in repo_data is a dict with 'alias' and 'url' keys.
    Raises ValueError if not.
    """
    for group, entries in repo_data.items():
        if not isinstance(entries, list):
            raise ValueError(f"Group '{group}' is not a list.")
        for idx, entry in enumerate(entries):
            if not isinstance(entry, dict):
                raise ValueError(f"Entry {idx+1} in group '{group}' is not a dict: {entry}")
            missing = [key for key in ("alias", "url") if key not in entry]
            if missing:
                raise ValueError(f"Entry {idx+1} in group '{group}' missing {', '.join(missing)}: {entry}")

# -------------------------------------------------------------------------- }}}
# {{{ Print help.

def print_help():
    """
    Show CLI usage.
    """
    print(f"{ICON_INFO} Usage: gits [-h -l -R] [-r name -d -s -u -v -x] [-c | -p] [-n]\n")
    print("Options:")
    print("  -h          Show help")
    print("  -l          List repository locations")
    print("  -R          Apply modifiers to repository locations")
    print("Repository Locations")
    print("  -r name")
    print("Modifiers")
    print("  -d          Delete repository location")
    print("  -s          List repositories with stash entries")
    print("  -u          Convert UTF-16 files to UTF-8")
    print("  -v          Verbose output")
    print("  -x          Clean untracked files")
    print("Mutually exclusive actions")
    print("  -c          Clone repositories defined in repository locations array")
    print("  -p          Pull repositories with safe stashing")
    print("Dry-run")
    print("  -n          Dry-run (simulate actions)")

# -------------------------------------------------------------------------- }}}
# {{{ List Repositories

def list_repos(repo_data):
    """
    List only the group names found in the YAML.
    """
    print(f"{ICON_INFO} Repository locations:\n")
    for group in repo_data.keys():
        print(f"  {ICON_INFO} {group}")
    print()

# -------------------------------------------------------------------------- }}}
# {{{ Iterate Over Repositories Directories

def iter_repo_dirs(repo_data, options):
    """
    Yield (group, alias, repo_dir) for each repo in (optionally) selected group.
    """
    home = os.path.expanduser("~")
    for group, entries in repo_data.items():
        if options.r and group != options.r:
            continue
        for entry in entries:
            alias = entry["alias"]
            repo_dir = os.path.join(home, group, alias)
            yield group, alias, repo_dir

# -------------------------------------------------------------------------- }}}
# {{{ Clone a repository

def clone_repo(url, alias, group, verbose=False, dry_run=False):
    """
    Clone a single repository.
    """
    home = os.path.expanduser("~")
    dest_dir = os.path.join(home, group, alias)
    if os.path.exists(dest_dir) and os.listdir(dest_dir):
        return (alias, url, dest_dir, "SKIPPED", 0, "Directory not empty")
    if dry_run:
        return (alias, url, dest_dir, "DRY-RUN", 0, "")
    os.makedirs(os.path.dirname(dest_dir), exist_ok=True)
    cmd = ["git", "clone", url, dest_dir]
    try:
        if verbose:
            print(f"{ICON_CLONE} Cloning {url} to {dest_dir}")
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            return (alias, url, dest_dir, "SUCCESS", 0, "")
        else:
            return (alias, url, dest_dir, "FAIL", result.returncode, result.stderr)
    except Exception as e:
        return (alias, url, dest_dir, "FAIL", -1, str(e))

# -------------------------------------------------------------------------- }}}
# {{{ Clone all repository

def clone_all_repos(repo_data, options):
    """
    Clone all repositories (optionally, only in selected group), in parallel.
    """
    max_workers = 4
    jobs = []
    for group, entries in repo_data.items():
        if options.r and group != options.r:
            continue
        for entry in entries:
            jobs.append((entry["url"], entry["alias"], group))
    print(f"{ICON_CLONE} Cloning {len(jobs)} repositories (parallel={max_workers})...\n")
    results = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_job = {
            executor.submit(clone_repo, url, alias, group, options.v, options.n): (alias, url, group)
            for url, alias, group in jobs
        }
        for future in as_completed(future_to_job):
            alias, url, dest_dir, status, code, msg = future.result()
            group = dest_dir.split("/")[-2] if "/" in dest_dir else ""
            if status == "SUCCESS":
                icon = ICON_SUCCESS
            elif status == "FAIL":
                icon = ICON_ERROR
            elif status == "SKIPPED":
                icon = ICON_WARNING
            elif status == "DRY-RUN":
                icon = ICON_INFO
            else:
                icon = ICON_INFO
            print(f"{icon} {group}/{alias:12} {url}")
            if status == "FAIL":
                print(f"    {ICON_ERROR} Error: {msg.strip()}")
            if status == "SKIPPED":
                print(f"    {ICON_WARNING} Skipped: {msg.strip()}")
    print(f"\n{ICON_DONE} Clone complete.")

# -------------------------------------------------------------------------- }}}
# {{{ Delete all repository

def delete_all_repos(repo_data, options):
    """
    Remove the entire group directory for each group in repo_data.
    (Deletes ~/group and all contents, with icons.)
    """
    home = os.path.expanduser("~")
    count = 0
    for group in repo_data.keys():
        if options.r and group != options.r:
            continue
        group_dir = os.path.join(home, group)
        if os.path.isdir(group_dir):
            print(f"{ICON_DELETE} {group_dir}")
            count += 1
            if not options.n:
                try:
                    shutil.rmtree(group_dir)
                    print(f"    {ICON_DONE} Removed.")
                except Exception as e:
                    print(f"    {ICON_ERROR} Error removing: {e}")
            else:
                print(f"    {ICON_INFO} (Dry-run; not removed)")
        else:
            if options.v:
                print(f"{ICON_WARNING} [NOT FOUND] {group_dir}")
    if count == 0:
        print(f"{ICON_WARNING} No repository groups found to delete.")
    else:
        print(f"\n{ICON_DONE} Delete complete. {count} group(s) processed.")

# -------------------------------------------------------------------------- }}}
# {{{ Pull a repository

def pull_repo(group, alias, repo_dir, verbose=False, dry_run=False):
    """
    Pull changes for a repo, stashing local changes if necessary.
    """
    if not os.path.isdir(repo_dir):
        return (alias, group, "NOT_FOUND", None)
    if dry_run:
        return (alias, group, "DRY-RUN", None)
    try:
        changed = subprocess.run(
            ["git", "-C", repo_dir, "status", "--porcelain"],
            capture_output=True, text=True)
        stashed = False
        if changed.stdout.strip():
            stash = subprocess.run(
                ["git", "-C", repo_dir, "stash"], capture_output=True, text=True)
            stashed = "No local changes" not in stash.stdout
            if verbose:
                print(f"{ICON_STASH} [{group}/{alias}] Stashed local changes")
        pull = subprocess.run(
            ["git", "-C", repo_dir, "pull"], capture_output=True, text=True)
        if pull.returncode != 0:
            return (alias, group, "FAIL", pull.stderr)
        if stashed:
            subprocess.run(
                ["git", "-C", repo_dir, "stash", "pop"], capture_output=True, text=True)
            if verbose:
                print(f"{ICON_STASH} [{group}/{alias}] Popped stash after pull")
        return (alias, group, "SUCCESS", None)
    except Exception as e:
        return (alias, group, "FAIL", str(e))

# -------------------------------------------------------------------------- }}}
# {{{ Pull all repositories

def pull_all_repos(repo_data, options):
    """
    Pull all repositories (optionally, only in selected group), in parallel.
    """
    max_workers = 4
    jobs = list(iter_repo_dirs(repo_data, options))
    print(f"{ICON_PULL} Pulling {len(jobs)} repositories (parallel={max_workers})...\n")
    results = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_job = {
            executor.submit(pull_repo, group, alias, repo_dir, options.v, options.n): (alias, group)
            for group, alias, repo_dir in jobs
        }
        for future in as_completed(future_to_job):
            alias, group, status, msg = future.result()
            if status == "SUCCESS":
                icon = ICON_SUCCESS
            elif status == "FAIL":
                icon = ICON_ERROR
            elif status == "DRY-RUN":
                icon = ICON_INFO
            elif status == "NOT_FOUND":
                icon = ICON_WARNING
            else:
                icon = ICON_INFO
            print(f"{icon} {group}/{alias}")
            if msg and status == "FAIL":
                print(f"    {ICON_ERROR} Error: {msg.strip()}")
    print(f"\n{ICON_DONE} Pull complete.")

# -------------------------------------------------------------------------- }}}
# {{{ List repositories with stashes.

def list_stashed_repos(repo_data, options):
    """
    List repositories which have stash entries.
    """
    jobs = list(iter_repo_dirs(repo_data, options))
    found = False
    for group, alias, repo_dir in jobs:
        if not os.path.isdir(repo_dir):
            continue
        result = subprocess.run(
            ["git", "-C", repo_dir, "stash", "list"],
            capture_output=True, text=True)
        if result.stdout.strip():
            print(f"{ICON_STASH} {group}/{alias} has stashes:")
            print(result.stdout)
            found = True
    if not found:
        print(f"{ICON_INFO} No stashed entries found in any repository.")

# -------------------------------------------------------------------------- }}}
# {{{ Clean a repository untracked files.

def clean_untracked_repo(group, alias, repo_dir, verbose=False, dry_run=False):
    """
    Remove all untracked files from a repo (git clean -fd).
    """
    if not os.path.isdir(repo_dir):
        return (alias, group, "NOT_FOUND", None)
    if dry_run:
        return (alias, group, "DRY-RUN", None)
    result = subprocess.run(
        ["git", "-C", repo_dir, "clean", "-fd"],
        capture_output=True, text=True)
    if result.returncode == 0:
        return (alias, group, "CLEANED", None)
    else:
        return (alias, group, "FAIL", result.stderr)

# -------------------------------------------------------------------------- }}}
# {{{ Clean all repositories untracked files.

def clean_all_repos(repo_data, options):
    """
    Remove untracked files from all repositories.
    """
    max_workers = 4
    jobs = list(iter_repo_dirs(repo_data, options))
    print(f"{ICON_CLEAN} Cleaning untracked files in {len(jobs)} repositories (parallel={max_workers})...\n")
    results = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_job = {
            executor.submit(clean_untracked_repo, group, alias, repo_dir, options.v, options.n): (alias, group)
            for group, alias, repo_dir in jobs
        }
        for future in as_completed(future_to_job):
            alias, group, status, msg = future.result()
            if status == "CLEANED":
                icon = ICON_DONE
            elif status == "FAIL":
                icon = ICON_ERROR
            elif status == "DRY-RUN":
                icon = ICON_INFO
            elif status == "NOT_FOUND":
                icon = ICON_WARNING
            else:
                icon = ICON_INFO
            print(f"{icon} {group}/{alias}")
            if msg and status == "FAIL":
                print(f"    {ICON_ERROR} Error: {msg.strip()}")
    print(f"\n{ICON_DONE} Clean complete.")

# -------------------------------------------------------------------------- }}}
# {{{ Convert uft16 to utf8 files in a repository.

def convert_utf16_to_utf8_in_repo(group, alias, repo_dir, verbose=False, dry_run=False):
    """
    Recursively convert UTF-16 files to UTF-8 in a repo.
    Only files with UTF-16 BOM (little/big endian) are converted.
    """
    if not os.path.isdir(repo_dir):
        return (alias, group, "NOT_FOUND", 0)
    converted_files = 0
    for root, _, files in os.walk(repo_dir):
        for fname in files:
            path = os.path.join(root, fname)
            try:
                with open(path, "rb") as f:
                    raw = f.read(4)
                    if raw.startswith(b'\xff\xfe') or raw.startswith(b'\xfe\xff'):
                        if dry_run:
                            converted_files += 1
                            if verbose:
                                print(f"{ICON_CONVERT} (Dry-run) Would convert: {path}")
                            continue
                        with open(path, "r", encoding="utf-16") as fi:
                            data = fi.read()
                        with open(path, "w", encoding="utf-8") as fo:
                            fo.write(data)
                        converted_files += 1
                        if verbose:
                            print(f"{ICON_CONVERT} Converted: {path}")
            except Exception as e:
                if verbose:
                    print(f"{ICON_WARNING} Failed to check/convert {path}: {e}")
    return (alias, group, "CONVERTED", converted_files)

# -------------------------------------------------------------------------- }}}
# {{{ Convert uft16 to utf8 files in all repository.


def convert_all_utf16(repo_data, options):
    """
    Convert all UTF-16 files to UTF-8 in all repositories (parallel).
    """
    max_workers = 4
    jobs = list(iter_repo_dirs(repo_data, options))
    print(f"{ICON_CONVERT} Checking for UTF-16 files in {len(jobs)} repositories (parallel={max_workers})...\n")
    results = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_job = {
            executor.submit(convert_utf16_to_utf8_in_repo, group, alias, repo_dir, options.v, options.n): (alias, group)
            for group, alias, repo_dir in jobs
        }
        for future in as_completed(future_to_job):
            alias, group, status, converted = future.result()
            icon = ICON_DONE if converted else ICON_INFO
            print(f"{icon} {group}/{alias} files converted: {converted}")
    total = sum(r[3] for r in results if isinstance(r[3], int))
    print(f"\n{ICON_DONE} UTF-16 to UTF-8 conversion complete.")

# -------------------------------------------------------------------------- }}}
# {{{ Load and validae repository location file.

def load_and_validate_repo_data():
    """
    Loads and validates the repository_locations.yml config file.
    Exits with a clear error message if missing or malformed.
    Returns:
        repo_data (dict): Validated repo data from YAML.
    """
    repository_locations_path = os.path.expanduser("~/.config/gits/repository_locations.yml")
    repo_data = load_repos_yaml(repository_locations_path)
    try:
        validate_repo_data(repo_data)
    except ValueError as err:
        print(f"{ICON_ERROR} YAML validation error: {err}")
        sys.exit(1)
    return repo_data

# -------------------------------------------------------------------------- }}}
# {{{ CLI dispatch with match/case

def dispatch_command(repo_data, options):
    """
    Dispatch CLI command using Python 3.10+ match/case for clarity and future extensibility.
    """
    max_workers = 4

    match True:
        case _ if options.h:
            print_help()
            sys.exit(0)

        case _ if options.l:
            list_repos(repo_data)
            sys.exit(0)

        case _ if options.c:
            clone_all_repos(repo_data, options)
            sys.exit(0)

        case _ if options.d:
            delete_all_repos(repo_data, options)
            sys.exit(0)

        case _ if options.p:
            pull_all_repos(repo_data, options)
            sys.exit(0)

        case _ if options.s:
            list_stashed_repos(repo_data, options)
            sys.exit(0)

        case _ if options.x:
            clean_all_repos(repo_data, options)
            sys.exit(0)

        case _ if options.u:
            convert_all_utf16(repo_data, options)
            sys.exit(0)

# -------------------------------------------------------------------------- }}}
# {{{ Main orchestrates the show.

def main():
    options = Options(parse_args())
    repo_data = load_and_validate_repo_data()
    dispatch_command(repo_data, options)

if __name__ == '__main__':
    main()

# -------------------------------------------------------------------------- }}}
