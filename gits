#!/usr/bin/env python3
"""
gits.py - Python version of 'gits' repository management script, with icons.

Features:
  - Pre-flight YAML validation (clear errors for malformed config)
  - Clone, delete, pull, clean, convert encoding, list stashes, and more
  - All repo directories are in $HOME/group/alias
  - Parallel actions, dry-run and verbose support
  - Beautiful, informative icons for every status/action

Author: Traap
Date: 2025-05-18
"""

import argparse
import sys
import os
import yaml
import subprocess
import shutil
from concurrent.futures import ThreadPoolExecutor, as_completed

# ---- ICONS ----
ICON_CLEAN    = "üßπ"
ICON_CLONE    = "‚û°Ô∏è"
ICON_CONVERT  = "üîÑ"
ICON_DELETE   = "‚ùå"
ICON_DONE     = "‚úÖ"
ICON_ERROR    = "‚ùå"
ICON_INFO     = "‚ÑπÔ∏è"
ICON_PULL     = "‚¨ÜÔ∏è"
ICON_STASH    = "üì¶"
ICON_SUCCESS  = "‚úÖ"
ICON_TIME     = "‚è±Ô∏è"
ICON_WARNING  = "‚ö†Ô∏è"

def load_repos_yaml(filepath):
    """
    Load the repository locations YAML file.
    """
    if not os.path.exists(filepath):
        print(f"{ICON_ERROR} Repo locations file not found: {filepath}")
        sys.exit(1)
    with open(filepath, 'r') as f:
        return yaml.safe_load(f)

def validate_repo_data(repo_data):
    """
    Ensures every entry in repo_data is a dict with 'alias' and 'url' keys.
    Raises ValueError if not.
    """
    for group, entries in repo_data.items():
        if not isinstance(entries, list):
            raise ValueError(f"Group '{group}' is not a list.")
        for idx, entry in enumerate(entries):
            if not isinstance(entry, dict):
                raise ValueError(f"Entry {idx+1} in group '{group}' is not a dict: {entry}")
            missing = [key for key in ("alias", "url") if key not in entry]
            if missing:
                raise ValueError(f"Entry {idx+1} in group '{group}' missing {', '.join(missing)}: {entry}")

def print_help():
    """
    Show help text, falling back to CLI usage if gits-help.txt not found.
    """
    help_path = os.path.join(os.path.dirname(__file__), "gits-help.txt")
    if os.path.isfile(help_path):
        with open(help_path) as f:
            print(f.read())
    else:
        print(f"{ICON_INFO} Usage: gits [-h -l -R] [-r name -d -s -u -v -x] [-c | -p] [-n]\n")
        print("Options:")
        print("  -h          Show help")
        print("  -l          List repository locations")
        print("  -R          Apply modifiers to repository locations")
        print("Repository Locations")
        print("  -r name")
        print("Modifiers")
        print("  -d          Delete repository location")
        print("  -s          List repositories with stash entries")
        print("  -u          Convert UTF-16 files to UTF-8")
        print("  -v          Verbose output")
        print("  -x          Clean untracked files")
        print("Mutually exclusive actions")
        print("  -c          Clone repositories defined in repository locations array")
        print("  -p          Pull repositories with safe stashing")
        print("Dry-run")
        print("  -n          Dry-run (simulate actions)")

def list_repos(repo_data):
    """
    List only the group names found in the YAML.
    """
    print(f"{ICON_INFO} Repository locations:\n")
    for group in repo_data.keys():
        print(f"  {ICON_INFO} {group}")
    print()

def iter_repo_dirs(repo_data, selected_group=None):
    """
    Yield (group, alias, repo_dir) for each repo in (optionally) selected group.
    """
    home = os.path.expanduser("~")
    for group, entries in repo_data.items():
        if selected_group and group != selected_group:
            continue
        for entry in entries:
            alias = entry["alias"]
            repo_dir = os.path.join(home, group, alias)
            yield group, alias, repo_dir

def clone_repo(url, alias, group, verbose=False, dry_run=False):
    """
    Clone a single repository.
    """
    home = os.path.expanduser("~")
    dest_dir = os.path.join(home, group, alias)
    if os.path.exists(dest_dir) and os.listdir(dest_dir):
        return (alias, url, dest_dir, "SKIPPED", 0, "Directory not empty")
    if dry_run:
        return (alias, url, dest_dir, "DRY-RUN", 0, "")
    os.makedirs(os.path.dirname(dest_dir), exist_ok=True)
    cmd = ["git", "clone", url, dest_dir]
    try:
        if verbose:
            print(f"{ICON_CLONE} Cloning {url} to {dest_dir}")
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            return (alias, url, dest_dir, "SUCCESS", 0, "")
        else:
            return (alias, url, dest_dir, "FAIL", result.returncode, result.stderr)
    except Exception as e:
        return (alias, url, dest_dir, "FAIL", -1, str(e))

def clone_all_repos(repo_data, selected_group=None, verbose=False, dry_run=False, max_workers=4):
    """
    Clone all repositories (optionally, only in selected group), in parallel.
    """
    jobs = []
    for group, entries in repo_data.items():
        if selected_group and group != selected_group:
            continue
        for entry in entries:
            jobs.append((entry["url"], entry["alias"], group))
    print(f"{ICON_CLONE} Cloning {len(jobs)} repositories (parallel={max_workers})...\n")
    results = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_job = {
            executor.submit(clone_repo, url, alias, group, verbose, dry_run): (alias, url, group)
            for url, alias, group in jobs
        }
        for future in as_completed(future_to_job):
            alias, url, dest_dir, status, code, msg = future.result()
            group = dest_dir.split("/")[-2] if "/" in dest_dir else ""
            if status == "SUCCESS":
                icon = ICON_SUCCESS
            elif status == "FAIL":
                icon = ICON_ERROR
            elif status == "SKIPPED":
                icon = ICON_WARNING
            elif status == "DRY-RUN":
                icon = ICON_INFO
            else:
                icon = ICON_INFO
            print(f"{icon} {group}/{alias:12} {url}")
            if status == "FAIL":
                print(f"    {ICON_ERROR} Error: {msg.strip()}")
            if status == "SKIPPED":
                print(f"    {ICON_WARNING} Skipped: {msg.strip()}")
    print(f"\n{ICON_DONE} Clone complete.")

def delete_all_repos(repo_data, selected_group=None, verbose=False, dry_run=False):
    """
    Remove the entire group directory for each group in repo_data.
    (Deletes ~/group and all contents, with icons.)
    """
    home = os.path.expanduser("~")
    count = 0
    for group in repo_data.keys():
        if selected_group and group != selected_group:
            continue
        group_dir = os.path.join(home, group)
        if os.path.isdir(group_dir):
            print(f"{ICON_DELETE} {group_dir}")
            count += 1
            if not dry_run:
                try:
                    shutil.rmtree(group_dir)
                    print(f"    {ICON_DONE} Removed.")
                except Exception as e:
                    print(f"    {ICON_ERROR} Error removing: {e}")
            else:
                print(f"    {ICON_INFO} (Dry-run; not removed)")
        else:
            if verbose:
                print(f"{ICON_WARNING} [NOT FOUND] {group_dir}")
    if count == 0:
        print(f"{ICON_WARNING} No repository groups found to delete.")
    else:
        print(f"\n{ICON_DONE} Delete complete. {count} group(s) processed.")

def pull_repo(group, alias, repo_dir, verbose=False, dry_run=False):
    """
    Pull changes for a repo, stashing local changes if necessary.
    """
    if not os.path.isdir(repo_dir):
        return (alias, group, "NOT_FOUND", None)
    if dry_run:
        return (alias, group, "DRY-RUN", None)
    try:
        changed = subprocess.run(
            ["git", "-C", repo_dir, "status", "--porcelain"],
            capture_output=True, text=True)
        stashed = False
        if changed.stdout.strip():
            stash = subprocess.run(
                ["git", "-C", repo_dir, "stash"], capture_output=True, text=True)
            stashed = "No local changes" not in stash.stdout
            if verbose:
                print(f"{ICON_STASH} [{group}/{alias}] Stashed local changes")
        pull = subprocess.run(
            ["git", "-C", repo_dir, "pull"], capture_output=True, text=True)
        if pull.returncode != 0:
            return (alias, group, "FAIL", pull.stderr)
        if stashed:
            subprocess.run(
                ["git", "-C", repo_dir, "stash", "pop"], capture_output=True, text=True)
            if verbose:
                print(f"{ICON_STASH} [{group}/{alias}] Popped stash after pull")
        return (alias, group, "SUCCESS", None)
    except Exception as e:
        return (alias, group, "FAIL", str(e))

def pull_all_repos(repo_data, selected_group=None, verbose=False, dry_run=False, max_workers=4):
    """
    Pull all repositories (optionally, only in selected group), in parallel.
    """
    jobs = list(iter_repo_dirs(repo_data, selected_group))
    print(f"{ICON_PULL} Pulling {len(jobs)} repositories (parallel={max_workers})...\n")
    results = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_job = {
            executor.submit(pull_repo, group, alias, repo_dir, verbose, dry_run): (alias, group)
            for group, alias, repo_dir in jobs
        }
        for future in as_completed(future_to_job):
            alias, group, status, msg = future.result()
            if status == "SUCCESS":
                icon = ICON_SUCCESS
            elif status == "FAIL":
                icon = ICON_ERROR
            elif status == "DRY-RUN":
                icon = ICON_INFO
            elif status == "NOT_FOUND":
                icon = ICON_WARNING
            else:
                icon = ICON_INFO
            print(f"{icon} {group}/{alias}")
            if msg and status == "FAIL":
                print(f"    {ICON_ERROR} Error: {msg.strip()}")
    print(f"\n{ICON_DONE} Pull complete.")

def list_stashed_repos(repo_data, selected_group=None, verbose=False):
    """
    List repositories which have stash entries.
    """
    jobs = list(iter_repo_dirs(repo_data, selected_group))
    found = False
    for group, alias, repo_dir in jobs:
        if not os.path.isdir(repo_dir):
            continue
        result = subprocess.run(
            ["git", "-C", repo_dir, "stash", "list"],
            capture_output=True, text=True)
        if result.stdout.strip():
            print(f"{ICON_STASH} {group}/{alias} has stashes:")
            print(result.stdout)
            found = True
    if not found:
        print(f"{ICON_INFO} No stashed entries found in any repository.")

def clean_untracked_repo(group, alias, repo_dir, verbose=False, dry_run=False):
    """
    Remove all untracked files from a repo (git clean -fd).
    """
    if not os.path.isdir(repo_dir):
        return (alias, group, "NOT_FOUND", None)
    if dry_run:
        return (alias, group, "DRY-RUN", None)
    result = subprocess.run(
        ["git", "-C", repo_dir, "clean", "-fd"],
        capture_output=True, text=True)
    if result.returncode == 0:
        return (alias, group, "CLEANED", None)
    else:
        return (alias, group, "FAIL", result.stderr)

def clean_all_repos(repo_data, selected_group=None, verbose=False, dry_run=False, max_workers=4):
    """
    Remove untracked files from all repositories.
    """
    jobs = list(iter_repo_dirs(repo_data, selected_group))
    print(f"{ICON_CLEAN} Cleaning untracked files in {len(jobs)} repositories (parallel={max_workers})...\n")
    results = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_job = {
            executor.submit(clean_untracked_repo, group, alias, repo_dir, verbose, dry_run): (alias, group)
            for group, alias, repo_dir in jobs
        }
        for future in as_completed(future_to_job):
            alias, group, status, msg = future.result()
            if status == "CLEANED":
                icon = ICON_DONE
            elif status == "FAIL":
                icon = ICON_ERROR
            elif status == "DRY-RUN":
                icon = ICON_INFO
            elif status == "NOT_FOUND":
                icon = ICON_WARNING
            else:
                icon = ICON_INFO
            print(f"{icon} {group}/{alias}")
            if msg and status == "FAIL":
                print(f"    {ICON_ERROR} Error: {msg.strip()}")
    print(f"\n{ICON_DONE} Clean complete.")

def convert_utf16_to_utf8_in_repo(group, alias, repo_dir, verbose=False, dry_run=False):
    """
    Recursively convert UTF-16 files to UTF-8 in a repo.
    Only files with UTF-16 BOM (little/big endian) are converted.
    """
    if not os.path.isdir(repo_dir):
        return (alias, group, "NOT_FOUND", 0)
    converted_files = 0
    for root, _, files in os.walk(repo_dir):
        for fname in files:
            path = os.path.join(root, fname)
            try:
                with open(path, "rb") as f:
                    raw = f.read(4)
                    if raw.startswith(b'\xff\xfe') or raw.startswith(b'\xfe\xff'):
                        if dry_run:
                            converted_files += 1
                            if verbose:
                                print(f"{ICON_CONVERT} (Dry-run) Would convert: {path}")
                            continue
                        with open(path, "r", encoding="utf-16") as fi:
                            data = fi.read()
                        with open(path, "w", encoding="utf-8") as fo:
                            fo.write(data)
                        converted_files += 1
                        if verbose:
                            print(f"{ICON_CONVERT} Converted: {path}")
            except Exception as e:
                if verbose:
                    print(f"{ICON_WARNING} Failed to check/convert {path}: {e}")
    return (alias, group, "CONVERTED", converted_files)

def convert_all_utf16(repo_data, selected_group=None, verbose=False, dry_run=False, max_workers=4):
    """
    Convert all UTF-16 files to UTF-8 in all repositories (parallel).
    """
    jobs = list(iter_repo_dirs(repo_data, selected_group))
    print(f"{ICON_CONVERT} Checking for UTF-16 files in {len(jobs)} repositories (parallel={max_workers})...\n")
    results = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_job = {
            executor.submit(convert_utf16_to_utf8_in_repo, group, alias, repo_dir, verbose, dry_run): (alias, group)
            for group, alias, repo_dir in jobs
        }
        for future in as_completed(future_to_job):
            alias, group, status, converted = future.result()
            icon = ICON_DONE if converted else ICON_INFO
            print(f"{icon} {group}/{alias} files converted: {converted}")
    total = sum(r[3] for r in results if isinstance(r[3], int))
    print(f"\n{ICON_DONE} UTF-16 to UTF-8 conversion complete.")

def main():
    """
    Parse arguments and dispatch to feature.
    """
    parser = argparse.ArgumentParser(add_help=False, usage=argparse.SUPPRESS)
    parser.add_argument('-h', action='store_true')
    parser.add_argument('-l', action='store_true')
    parser.add_argument('-R', action='store_true')
    parser.add_argument('-r', metavar='name', type=str)
    parser.add_argument('-d', action='store_true')
    parser.add_argument('-s', action='store_true')
    parser.add_argument('-u', action='store_true')
    parser.add_argument('-v', action='store_true')
    parser.add_argument('-x', action='store_true')
    group = parser.add_mutually_exclusive_group()
    group.add_argument('-c', action='store_true')
    group.add_argument('-p', action='store_true')
    parser.add_argument('-n', action='store_true')
    args = parser.parse_args()

    repository_locations_path = os.path.expanduser("~/.config/gits/repository_locations.yml")

    if args.h:
        print_help()
        sys.exit(0)

    repo_data = None
    if args.l or args.R or args.r or args.c or args.p or args.d or args.s or args.u or args.x:
        repo_data = load_repos_yaml(repository_locations_path)
        try:
            validate_repo_data(repo_data)
        except ValueError as err:
            print(f"{ICON_ERROR} YAML validation error: {err}")
            sys.exit(1)

    if args.l:
        list_repos(repo_data)
        sys.exit(0)

    if args.c:
        max_workers = 4
        clone_all_repos(
            repo_data,
            selected_group=args.r,
            verbose=args.v,
            dry_run=args.n,
            max_workers=max_workers
        )
        sys.exit(0)

    if args.d:
        delete_all_repos(
            repo_data,
            selected_group=args.r,
            verbose=args.v,
            dry_run=args.n
        )
        sys.exit(0)

    if args.p:
        pull_all_repos(
            repo_data,
            selected_group=args.r,
            verbose=args.v,
            dry_run=args.n
        )
        sys.exit(0)

    if args.s:
        list_stashed_repos(
            repo_data,
            selected_group=args.r,
            verbose=args.v
        )
        sys.exit(0)

    if args.x:
        clean_all_repos(
            repo_data,
            selected_group=args.r,
            verbose=args.v,
            dry_run=args.n
        )
        sys.exit(0)

    if args.u:
        convert_all_utf16(
            repo_data,
            selected_group=args.r,
            verbose=args.v,
            dry_run=args.n
        )
        sys.exit(0)

    # Remaining unimplemented features (if any)
    if args.R:
        print(f"{ICON_WARNING} Apply to all repository locations (to be implemented)")
    if args.r:
        print(f"{ICON_INFO} Selected repository location: {args.r} (to be implemented)")
    if args.v:
        print(f"{ICON_INFO} Verbose output (to be implemented)")
    if args.n and not (args.c or args.d or args.p or args.x or args.u):
        print(f"{ICON_INFO} Dry-run mode (to be implemented)")

if __name__ == '__main__':
    main()

